client_token=
client_text_channel='stellas-output'

com_voice_channel='Hang with Stella'
com_text_channel='stellas-output'
com_min_audio_len=500
com_end_speaking_delay=200
com_interrupt_time=100

STT_host='pd'
STT_port=10300

TTS_host='pd'
TTS_port=10200

LLM_host='pd'
LLM_port=6900
LLM_api_key='NULL'
LLM_server_type='ollama'
LLM_SFW=2
LLM_speaker_pause_time=.5
LLM_message_history_privacy=1
LLM_temperature=.7 #randomness of response, confused with creativity

# going with 75% for conversaion and 25% for thinking
# thought responses will be half of the chat responses. 
# 256 is several minutes of speaking.
LLM_context_length = 32768
LLM_token_response = 256

LLM_model="llama3.1:8b-instruct-q4_K_M-32k"

LLM_prompt_format="llam3_1_instruct"
#LLM_prompt_format="chatml"
#LLM_prompt_format="qwen2_instruct"

sql_db_type = 'mariadb'
sql_db_sqlite_file = './discord.db'
sql_db_host = 'pd'
sql_db_port = 3306
sql_db_user = 'DiscordBot'
sql_db_password =
sql_db_database = 'Discord'

behavior_track_text_interrupt=0
behavior_command_prefix='.'
behavior_time_between_messages=1
behavior_TTS_enable=1

performance_show_timings=1
performance_show_text=0
performance_db_always_connected=1
